{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-08T23:02:02.105067Z","iopub.execute_input":"2023-06-08T23:02:02.105753Z","iopub.status.idle":"2023-06-08T23:02:02.119741Z","shell.execute_reply.started":"2023-06-08T23:02:02.105701Z","shell.execute_reply":"2023-06-08T23:02:02.117922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">\n    <h2>Project Scope</h2>\n        <ul>\n            <li>Using solar generation and associated temperature data to explore time series forecasting.</li>\n            <li>Compare the performance of ML models and a deep learning LSTM model to make a day-ahead forecast of power generation</li>\n            <li>See what impact including the temperature data has on the forecast</li>\n            <li>Experiment with feature engineering and test the impact differernt features have on the models</li>\n            <li>Fine tune the models</li>\n            <li>Report on what model is ultimately more successful and comment on possible project extensions</li>\n    </ul>\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">\n    <h2>Loading and exploring data</h2>\nThis data was taken from two solar plants in India over the course of 34 days in 15 minute intervals. The weather data is on the plant level (just measured from one sensor) and the generation data is gathered from individual inverters across the plant. More information can be found here: \n<a href=\"https://www.kaggle.com/datasets/anikannal/solar-power-generation-data\">Data Card</a>. Credit to \n<a href=\"https://www.kaggle.com/anikannal\">Ani Kannal</a> for uploading this dataset to Kaggle.\n</span>","metadata":{}},{"cell_type":"code","source":"df_plt1_gen = pd.read_csv('/kaggle/input/solar-power-generation-data/Plant_1_Generation_Data.csv')\ndf_plt2_gen = pd.read_csv('/kaggle/input/solar-power-generation-data/Plant_2_Generation_Data.csv')\ndf_plt1_weather = pd.read_csv('/kaggle/input/solar-power-generation-data/Plant_1_Weather_Sensor_Data.csv')\ndf_plt2_weather = pd.read_csv('/kaggle/input/solar-power-generation-data/Plant_2_Weather_Sensor_Data.csv')\n\ndf_plt1_gen.sample(10, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:02.148638Z","iopub.execute_input":"2023-06-08T23:02:02.150275Z","iopub.status.idle":"2023-06-08T23:02:02.394447Z","shell.execute_reply.started":"2023-06-08T23:02:02.150199Z","shell.execute_reply":"2023-06-08T23:02:02.393170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">PLANT_ID is the same throughout, so it can be safely removed. The generation is 0 for nighttime, which of course makes sense for solar power. Also, let's rename to sources to make them easier to track</span>","metadata":{}},{"cell_type":"code","source":"df_plt1_gen = df_plt1_gen.drop('PLANT_ID', axis=1)\ndf_plt1_gen['SOURCE_KEY'] = df_plt1_gen.SOURCE_KEY.map({df_plt1_gen.SOURCE_KEY.unique()[i-1]: f'Source_{i}' for i in range(1, len(df_plt1_gen.SOURCE_KEY.unique()) +1)})\ndf_plt1_gen.info()","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:02.396417Z","iopub.execute_input":"2023-06-08T23:02:02.396804Z","iopub.status.idle":"2023-06-08T23:02:02.616257Z","shell.execute_reply.started":"2023-06-08T23:02:02.396771Z","shell.execute_reply":"2023-06-08T23:02:02.614710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_plt1_gen.SOURCE_KEY","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:02.617857Z","iopub.execute_input":"2023-06-08T23:02:02.618316Z","iopub.status.idle":"2023-06-08T23:02:02.639639Z","shell.execute_reply.started":"2023-06-08T23:02:02.618283Z","shell.execute_reply":"2023-06-08T23:02:02.636305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">The dtypes make sense, but we'll need to make the DATE_TIME a datetime object for easier analysis. No nulls detected here, but there still could be outliers or nulls encoded in a different way.</span>","metadata":{}},{"cell_type":"code","source":"df_plt1_gen['DATE_TIME'] = pd.to_datetime(df_plt1_gen.DATE_TIME, format='%d-%m-%Y %H:%M')\ndf_plt1_gen.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:02.644521Z","iopub.execute_input":"2023-06-08T23:02:02.645139Z","iopub.status.idle":"2023-06-08T23:02:02.705233Z","shell.execute_reply.started":"2023-06-08T23:02:02.645093Z","shell.execute_reply":"2023-06-08T23:02:02.703147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">Now we can make some additional features out of the datetime object to aid in our analysis. If we were modeling throughout the year(s), month and year could be interesting to account for seasonal variation and long-term trends, but since our data only covers 34 days, we will omit them. We can use dayofyear to capture any longer trends that might be present.</span>","metadata":{}},{"cell_type":"code","source":"df_plt1_gen['HOUR'] = df_plt1_gen.DATE_TIME.dt.hour\ndf_plt1_gen['DAY'] = df_plt1_gen.DATE_TIME.dt.dayofyear\ndf_plt1_gen['DAY_WEEK'] = df_plt1_gen.DATE_TIME.dt.dayofweek\ndf_plt1_gen['DAY_FULL'] = df_plt1_gen.DATE_TIME.dt.day\ndf_plt1_gen['MINUTES'] = df_plt1_gen.DATE_TIME.dt.time\n#This maps the 15 minute intervals over the course of the day to ints 1-96. \ndf_plt1_gen['MINUTES'] = df_plt1_gen.MINUTES.map({df_plt1_gen.MINUTES.unique()[i-1]:i for i in range(1, 97)})","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:02.707005Z","iopub.execute_input":"2023-06-08T23:02:02.707535Z","iopub.status.idle":"2023-06-08T23:02:03.623138Z","shell.execute_reply.started":"2023-06-08T23:02:02.707489Z","shell.execute_reply":"2023-06-08T23:02:03.621379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">Next, let's check on the linear correlation of features</span>","metadata":{}},{"cell_type":"code","source":"corr = df_plt1_gen.corr(numeric_only=True)\ncorr","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:03.624969Z","iopub.execute_input":"2023-06-08T23:02:03.625477Z","iopub.status.idle":"2023-06-08T23:02:03.668688Z","shell.execute_reply.started":"2023-06-08T23:02:03.625430Z","shell.execute_reply":"2023-06-08T23:02:03.667076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">And why not make it a heatmap</span>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_palette('Spectral')\n\nsns.heatmap(corr, annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:03.673157Z","iopub.execute_input":"2023-06-08T23:02:03.673589Z","iopub.status.idle":"2023-06-08T23:02:04.386609Z","shell.execute_reply.started":"2023-06-08T23:02:03.673552Z","shell.execute_reply":"2023-06-08T23:02:04.384926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">Not surprisingly DC and AC power are highly correlated. This is good! It probably means the inverters in the plant are working correctly to convert the DC to AC. We will ultimately make AC_POWER our target and are probably safe to remove DC_POWER at this point. There is a strong correlation between HOUR and DAILY_YIELD, which makes sense as the daily yield increases throughout the day. Now we will look at a pairplot to see another representation of these relationships and look for any non-linear correlations.</span>","metadata":{}},{"cell_type":"code","source":"df_plt1_gen = df_plt1_gen.drop('DC_POWER', axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:04.388480Z","iopub.execute_input":"2023-06-08T23:02:04.388831Z","iopub.status.idle":"2023-06-08T23:02:04.400188Z","shell.execute_reply.started":"2023-06-08T23:02:04.388803Z","shell.execute_reply":"2023-06-08T23:02:04.398534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# g = sns.PairGrid(df_plt1_gen.sample(5000), diag_sharey=False, hue='SOURCE_KEY')\n# g.map_upper(sns.scatterplot, s=15)\n# g.map_lower(sns.kdeplot)\n# g.map_diag(sns.histplot)\n# #This takes quite a while to run, so saving this figure for future use.\n# plt.savefig(\"gen_pairgrid.png\", dpi=400)\nfrom IPython.display import Image, display\ndisplay(Image(filename='/kaggle/working/gen_pairgrid.png'))","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:04.402412Z","iopub.execute_input":"2023-06-08T23:02:04.403622Z","iopub.status.idle":"2023-06-08T23:02:04.861648Z","shell.execute_reply.started":"2023-06-08T23:02:04.403562Z","shell.execute_reply":"2023-06-08T23:02:04.860130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">There is A LOT of information to take in here! The zeros dominate the distribution for AC_POWER and DAILY_YIELD due to the nighttime. It looks like some data is missing based on the DAY/MINUTES pair. The inverters start to seperate out based on TOTAL_YIELD and DAILY_YIELD. This suggests the they are operating a different capacities; probably due to any number of factors: age, location within the plant, need for maintaince, etc. Exploring this more is outside the scope of this project, but could be a good starting point for another project. Finally, the connection between HOUR and AC_POWER is interesting and also makes sense with the peaks in the middle of the day. Let's explore this more next and also start to look for outliers.</span>","metadata":{}},{"cell_type":"markdown","source":"## Outliers","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">To explore outliers let's start by defining an outlier as \\< 1th percentile or \\> 99th percentile. To do this I will make four quantile features below: 2 of them in the outlier range and 2 to establish 1 standard deviation from the mean. Then we can plot the results. Let's also get the mean while we're at it.</span>","metadata":{}},{"cell_type":"code","source":"df_plt1_gen = df_plt1_gen.merge(df_plt1_gen.groupby('MINUTES').quantile(0.01, numeric_only=True).AC_POWER.rename('OUTLIERS_LOW_AC_POWER'), on='MINUTES', how='left')\ndf_plt1_gen = df_plt1_gen.merge(df_plt1_gen.groupby('MINUTES').quantile(0.99, numeric_only=True).AC_POWER.rename('OUTLIERS_HIGH_AC_POWER'), on='MINUTES', how='left')\ndf_plt1_gen = df_plt1_gen.merge(df_plt1_gen.groupby('MINUTES').mean(numeric_only=True).AC_POWER.rename('MEAN'), on='MINUTES', how='left')\ndf_plt1_gen = df_plt1_gen.merge(df_plt1_gen.groupby('MINUTES').std(numeric_only=True).AC_POWER.rename('STD'), on='MINUTES', how='left')\ndf_plt1_gen['STD_1'] = df_plt1_gen.query('AC_POWER < (MEAN + STD) and AC_POWER > (MEAN - STD)').AC_POWER","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:04.868633Z","iopub.execute_input":"2023-06-08T23:02:04.870561Z","iopub.status.idle":"2023-06-08T23:02:05.062547Z","shell.execute_reply.started":"2023-06-08T23:02:04.870494Z","shell.execute_reply":"2023-06-08T23:02:05.061327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.color_palette(\"Paired\")\nsns.scatterplot(data=df_plt1_gen, y='AC_POWER', x='MINUTES', hue='SOURCE_KEY', palette='gray', alpha=0.05, legend=False)\nsns.scatterplot(data=df_plt1_gen, y='STD_1', x='MINUTES', hue='SOURCE_KEY', palette='gray', alpha =0.5, legend=False)\nsns.scatterplot(data=df_plt1_gen.query('AC_POWER > OUTLIERS_HIGH_AC_POWER'), y='AC_POWER', x='MINUTES', hue='SOURCE_KEY', size='AC_POWER')\nsns.scatterplot(data=df_plt1_gen.query('AC_POWER < OUTLIERS_LOW_AC_POWER'), y='AC_POWER', x='MINUTES', hue='SOURCE_KEY', size= -df_plt1_gen.AC_POWER) \n\nplt.title('AC Power per 15 minutes')\nplt.ylabel('AC Power (kW)')\nplt.xlabel('Hour of Day')\nax.set_xticks([i for i in range(1, 97, 4)])\nax.set_xticklabels([i for i in range(24)])\nax.legend(['Full data', '+/- 1\\u03C3', 'Outliers'])","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:05.063958Z","iopub.execute_input":"2023-06-08T23:02:05.064340Z","iopub.status.idle":"2023-06-08T23:02:12.853928Z","shell.execute_reply.started":"2023-06-08T23:02:05.064308Z","shell.execute_reply":"2023-06-08T23:02:12.852382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">Interestingly, it looks like there are several instances where the power generated during the middle of the day was 0. This could either indicate bad data, malfunctioning invererters, some kind of planned maintence, really cloudy days, really sunny days where the plant is overheating/at capacity or any number of other things. Without having a deeper domain knowledge it it hard to know for sure, but let's see if we can find any pattern to these mid-day outliers.</span>\n","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">First, we'll check to see if any inverters in particular are responsible.","metadata":{}},{"cell_type":"code","source":"outliers_low = df_plt1_gen.query('AC_POWER < OUTLIERS_LOW_AC_POWER')\noutliers_high = df_plt1_gen.query('AC_POWER > OUTLIERS_HIGH_AC_POWER')\n\noutliers_source_low = outliers_low.groupby('SOURCE_KEY').count().DATE_TIME.reset_index().sort_values('DATE_TIME', ascending=False)\noutliers_source_low_zero = outliers_low[outliers_low.AC_POWER == 0].groupby('SOURCE_KEY').count().DATE_TIME.reset_index().sort_values('DATE_TIME', ascending=False)\nfig, ax = plt.subplots()\nsns.barplot(data = outliers_source_low, y='SOURCE_KEY', x='DATE_TIME', alpha = 0.5, )\nsns.barplot(data = outliers_source_low_zero, y='SOURCE_KEY', x='DATE_TIME')\nplt.title('Outlier Counts by Source (shading for 0.0 AC Power)')\nplt.ylabel('Source')\nplt.xlabel('Count')","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:12.855504Z","iopub.execute_input":"2023-06-08T23:02:12.855881Z","iopub.status.idle":"2023-06-08T23:02:13.407823Z","shell.execute_reply.started":"2023-06-08T23:02:12.855837Z","shell.execute_reply":"2023-06-08T23:02:13.406260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">The spread of outlier counts, including the 0.0 AC_POWER measurements are concentrated in sources 11 and 1. It could be that these were offline for an extended period due to maintance or malfunction. Below we'll look at the spread of the outliers with 0.0 AC_POWER measurements over the course of the full 34 days to see if there is any regularity.</span>","metadata":{}},{"cell_type":"code","source":"outliers_zero_count = outliers_low[outliers_low.AC_POWER == 0].groupby(['SOURCE_KEY','DAY']).count().rename(columns={'AC_POWER':'COUNTS'}).COUNTS.reset_index()\noutliers_zero_count\nfig, ax = plt.subplots(figsize=(8,5))\nsns.scatterplot(data=outliers_zero_count, x='DAY', y='COUNTS', hue='SOURCE_KEY', size='COUNTS', legend='brief')\nax.legend(bbox_to_anchor=(1, 1.05))\nax.set_xticks([i for i in range(135,170)])\nax.set_xticklabels([])\n","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:13.409850Z","iopub.execute_input":"2023-06-08T23:02:13.410250Z","iopub.status.idle":"2023-06-08T23:02:14.733003Z","shell.execute_reply.started":"2023-06-08T23:02:13.410219Z","shell.execute_reply":"2023-06-08T23:02:14.731402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">Several occur on the same day. There could have maintance that day or another issue.</span>","metadata":{}},{"cell_type":"code","source":"outliers_zero_count = outliers_low[outliers_low.AC_POWER == 0].groupby(['SOURCE_KEY','DAY_WEEK']).count().rename(columns={'AC_POWER':'COUNTS'}).COUNTS.reset_index()\noutliers_zero_count\nfig, ax = plt.subplots(figsize=(8,2.5))\nsns.scatterplot(data=outliers_zero_count, x='DAY_WEEK', y='COUNTS', hue='SOURCE_KEY', size='COUNTS', legend=False)\n# ax.legend(label='Sources', loc='upper left')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:14.735121Z","iopub.execute_input":"2023-06-08T23:02:14.735487Z","iopub.status.idle":"2023-06-08T23:02:15.052974Z","shell.execute_reply.started":"2023-06-08T23:02:14.735456Z","shell.execute_reply":"2023-06-08T23:02:15.051243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">Interestingly, several of the zeros occur on Sunday. This could still be coincidence or it might suggest some scheduled maintance, since Sunday is likely a day with less demand on the grid. Let's circle back and check on non-zero outliers as well.</span>","metadata":{}},{"cell_type":"code","source":"outliers_low_count = outliers_low.groupby(['SOURCE_KEY','DAY_WEEK']).count().rename(columns={'AC_POWER':'COUNTS'}).COUNTS.reset_index()\nfig, ax = plt.subplots(figsize=(8,2.5))\nsns.scatterplot(data=outliers_low_count, x='DAY_WEEK', y='COUNTS', hue='SOURCE_KEY', size='COUNTS', legend=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:15.054432Z","iopub.execute_input":"2023-06-08T23:02:15.054783Z","iopub.status.idle":"2023-06-08T23:02:15.407423Z","shell.execute_reply.started":"2023-06-08T23:02:15.054754Z","shell.execute_reply":"2023-06-08T23:02:15.405818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">There is a greater number of overall outliers on Monday. We might guess that after Sunday maintance there is a delay getting everything back online that goes into Monday. I think there is enough evidence now to choose to keep these outliers in out data as it might help the model account for some of this. That being said the number is low enough that it likely won't have too much of an impact.</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">The outliers representing the 99th percentile are not as much of a concern, as they seem well connected to the distribution and likely just indicate extra sunny/hot days. We can check this assumption by seeing how they lineup with the weather data. First, we'll load and take a quick look at the weather data.</span>","metadata":{}},{"cell_type":"markdown","source":"## Comparing 99th percentile outliers to weather data","metadata":{}},{"cell_type":"code","source":"df_plt1_weather.sample(10, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:15.409517Z","iopub.execute_input":"2023-06-08T23:02:15.409901Z","iopub.status.idle":"2023-06-08T23:02:15.432669Z","shell.execute_reply.started":"2023-06-08T23:02:15.409846Z","shell.execute_reply":"2023-06-08T23:02:15.430446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_plt1_weather.info()","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:15.435610Z","iopub.execute_input":"2023-06-08T23:02:15.436501Z","iopub.status.idle":"2023-06-08T23:02:15.464212Z","shell.execute_reply.started":"2023-06-08T23:02:15.436435Z","shell.execute_reply":"2023-06-08T23:02:15.461480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_plt1_weather.describe(include='all').T","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:15.468291Z","iopub.execute_input":"2023-06-08T23:02:15.470209Z","iopub.status.idle":"2023-06-08T23:02:15.518935Z","shell.execute_reply.started":"2023-06-08T23:02:15.469915Z","shell.execute_reply":"2023-06-08T23:02:15.517010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">The weather data looks pretty clean. We can remove the PLANT_ID and SOURCE_KEY, since they are the same throughout (as a reminder the weather data is only measured from a single source). Again, we should make the DATE_TIME a datetime object.</span>","metadata":{}},{"cell_type":"code","source":"df_plt1_weather = df_plt1_weather.drop(['PLANT_ID', 'SOURCE_KEY'], axis=1)\ndf_plt1_weather['DATE_TIME'] = pd.to_datetime(df_plt1_weather.DATE_TIME, format='%Y-%m-%d %H:%M:%S') ","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:15.520643Z","iopub.execute_input":"2023-06-08T23:02:15.521155Z","iopub.status.idle":"2023-06-08T23:02:15.533305Z","shell.execute_reply.started":"2023-06-08T23:02:15.521119Z","shell.execute_reply":"2023-06-08T23:02:15.531929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">Now we can join the weather data with our plant data on datetime.</span>","metadata":{}},{"cell_type":"code","source":"df_plt1_gen = df_plt1_gen.merge(df_plt1_weather, on='DATE_TIME', how='left')","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:15.535580Z","iopub.execute_input":"2023-06-08T23:02:15.536167Z","iopub.status.idle":"2023-06-08T23:02:15.589620Z","shell.execute_reply.started":"2023-06-08T23:02:15.536112Z","shell.execute_reply":"2023-06-08T23:02:15.588188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">To compare the temperatures to the outliers, let's first make a outlier feature that says whether or not a row is an outlier.</span>","metadata":{}},{"cell_type":"code","source":"df_plt1_gen['OUTLIER_HIGH_BOOL'] = (df_plt1_gen.AC_POWER > df_plt1_gen.OUTLIERS_HIGH_AC_POWER).astype('int')\ndf_plt1_gen['OUTLIER_LOW_BOOL'] = (df_plt1_gen.AC_POWER < df_plt1_gen.OUTLIERS_LOW_AC_POWER).astype('int')","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:15.591630Z","iopub.execute_input":"2023-06-08T23:02:15.592367Z","iopub.status.idle":"2023-06-08T23:02:15.606973Z","shell.execute_reply.started":"2023-06-08T23:02:15.592316Z","shell.execute_reply":"2023-06-08T23:02:15.605250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_plt1_gen['YEAR'] = df_plt1_gen.DATE_TIME.dt.year\nfig, (ax1, ax2) = plt.subplots(1, 2, sharex=True, sharey=True)\nsns.boxplot(data=df_plt1_gen, y='AMBIENT_TEMPERATURE', x='YEAR', hue='OUTLIER_HIGH_BOOL', ax=ax1)\nsns.boxplot(data=df_plt1_gen, y='AMBIENT_TEMPERATURE', x='YEAR', hue='OUTLIER_LOW_BOOL', ax=ax2, palette='rocket')\nplt.title('Ambient Temperature Distribution of Outliers vs rest of data')\nax1.legend(bbox_to_anchor=(2.5, .75))\nax2.legend(bbox_to_anchor=(1, 1))","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:15.610269Z","iopub.execute_input":"2023-06-08T23:02:15.611082Z","iopub.status.idle":"2023-06-08T23:02:16.378972Z","shell.execute_reply.started":"2023-06-08T23:02:15.611001Z","shell.execute_reply":"2023-06-08T23:02:16.376776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">These results do fit with what we would expect. The outliers with high power generation are on the high end of the ambiemt temperature distribution. And like we discovered earlier, the low power generation outliers, must have an explination other than the weather, since the are even above the mean of the ambient temp distribution. To quantify this some, we can perform a quick two-sample t-test.</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">For the 99th percentile outliers, we'll have a null hypothesis that the sample mean of the ambient temperature distribution across non-outliers is the same as sample mean of the ambient temperatures including the outliers; with the alternative hypothesis that the sample mean of the ambient temperature distribution across non-outliers is less than the sample mean of the ambient temperatures including the outliers. Let's have a typical threshold of 0.05.</span>","metadata":{}},{"cell_type":"code","source":"from scipy import stats\n\nstats, pval_high = stats.ttest_ind(np.array(df_plt1_gen.query('OUTLIER_HIGH_BOOL == 0').AMBIENT_TEMPERATURE), np.array(df_plt1_gen.query('OUTLIER_HIGH_BOOL == 1').AMBIENT_TEMPERATURE), alternative='less', equal_var=True, nan_policy='omit')\nprint(\"p-value for 99th percentile outliers: \", pval_high)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:16.381165Z","iopub.execute_input":"2023-06-08T23:02:16.382415Z","iopub.status.idle":"2023-06-08T23:02:16.422062Z","shell.execute_reply.started":"2023-06-08T23:02:16.382355Z","shell.execute_reply":"2023-06-08T23:02:16.420382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">With a p-value well below our significance level, we can safely reject the null hypothesis in favor of the alternative hypothesis that the sample mean of the ambient temperature distribution across non-outliers is less than the sample mean of the ambient temperatures including the outliers.</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">For the 1th percentile outliers, we'll have a null hypothesis that the sample mean of the ambient temperature distribution across non-outliers is the same as sample mean of the ambient temperatures including the outliers; with the alternative hypothesis that the sample mean of the ambient temperature distribution across non-outliers is greater than the sample mean of the ambient temperatures including the outliers. Let's again have a threshold of 0.05.</span>","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">","metadata":{}},{"cell_type":"code","source":"from scipy import stats\n\nstats, pval_low = stats.ttest_ind(np.array(df_plt1_gen.query('OUTLIER_LOW_BOOL == 0').AMBIENT_TEMPERATURE), np.array(df_plt1_gen.query('OUTLIER_LOW_BOOL == 1').AMBIENT_TEMPERATURE), alternative='greater', equal_var=True, nan_policy='omit')\nprint(\"p-value for 1th percentile outliers: \", np.round(pval_low, 4))","metadata":{"execution":{"iopub.status.busy":"2023-06-08T23:02:16.423555Z","iopub.execute_input":"2023-06-08T23:02:16.423924Z","iopub.status.idle":"2023-06-08T23:02:16.457165Z","shell.execute_reply.started":"2023-06-08T23:02:16.423893Z","shell.execute_reply":"2023-06-08T23:02:16.454944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-family:Roboto Mono;font-stretch:normal;font-style:normal;font-weight:200;word-spacing:-.225em;\">Now the p-value is clearly above our significance level, so we accept the null hypothesis that the sample mean of the ambient temperature distribution across non-outliers is the same as the sample mean of the ambient temperatures including the outliers. This lines up with our earlier speculation.</span>","metadata":{}}]}